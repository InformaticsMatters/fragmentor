---

# Graph combination process.
#
# Given one or more vendor or combination extracts this process creates a new Neo4j combination
# (a de-duplicated combination of the various node and edge files)
#
# The playbook: -
#
# - Downloads the individual or combined datasets
# - Then depending on the file, processing will:
# - - De-duplicate files that contain data where no merging is necessary.
# - - Merges files that contain data that must be de-duplicated and combined.
# - - Concatenates files that contain non-duplicate data.
# - Processes combined de-duplicated build.
# - Uploads the result as a new combination to S3
#
# Check that required command line parameters have been set:
# - deployment
# - Parameter file file containing the libraries has been created.
#
# e.g.
#
# runpath: /data/fragmentor/xchem_combi_20220202
# database_login_host: 130.246.214.154
# clean_start: yes
# clean_end: no
# deployment: production
#
# hardware:
#   production:
#     postgres_jobs: 20
#     parallel_jobs: 2500
#
# combine:
#    - lib:
#        path: 'extract/xchem_dsip/v2'
#        path: 'xchem_dsip'
#        data_source: disk
#    - lib:
#        path: 'extract/xchem_spot/v2'
#        data_source: s3
#        s3_bucket: im-fragnet
#        s3_access_key: "{{ lookup('env', 'AWS_ACCESS_KEY') }}"
#        s3_secret_key: "{{ lookup('env', 'AWS_SECRET_KEY') }}"
#        s3_region: "{{ lookup('env', 'AWS_REGION')|default('eu-central-1', true) }}"
#        s3_url: "{{ lookup('env', 'S3_URL') }}"
# path_out: 'xchem_combi_20220202'
# output_destination: s3
# s3_out_bucket: im-fragnet
# s3_out_bucket_requires_encryption: no
# s3_out_access_key: "{{ lookup('env', 'AWS_ACCESS_KEY') }}"
# s3_out_secret_key: "{{ lookup('env', 'AWS_SECRET_KEY') }}"
# s3_out_region: "{{ lookup('env', 'AWS_REGION')|default('eu-central-1', true) }}"
# s3_out_url: "{{ lookup('env', 'S3_URL') }}"
#
# ansible-playbook site-combine -e @parameters
#

- name: Assert user-variable definitions
  assert:
    that:
    - deployment|string|length > 0
    - deployment|string != 'SetMe'
    - "{{ combine[0].lib.path|string != 'SetMe'}}"
    - "{{ combine[0].lib.data_source|string != 'SetMe'}}"
    - "{{ output_destination|string != 'SetMe'}}"
    - runpath|string|length > 0
    - runpath|string != 'SetMe'
    fail_msg: You must provide a 'deployment', a list of extracts in a parameter file to combine and an output location.

- name: Assert sort memory
  assert:
    that:
    - nextflow_process_sort_memory_m|int >= 100

- name: List input datasets
  debug:
    msg: "{{ item.lib }}"
  loop: "{{ combine }}"

- import_tasks: initialise.yaml

#- include_tasks: "{{ role_path }}/../utils/tasks/send-mail.yaml"
#  vars:
#    mail_subject: >-
#      Play no. {{ cylc_play_number }} -
#      COLLECTING (1/4) - combination {{ combination_number }}

- import_tasks: download-datasets.yaml
- import_tasks: deduplicate.yaml
- import_tasks: merge.yaml
- import_tasks: concatenate.yaml

- name: Display compress_tasks
  debug:
    var: compress_tasks

- name: Check compress tasks finished.
  async_status: jid={{ compress_result.ansible_job_id }}
  register: job_result
  until: job_result.finished
  retries: "{{ (compress_timeout_minutes|int /
            compress_poll_period_minutes|int )|int }}"
  delay: "{{ compress_poll_period_minutes|int * 60 }}"
  loop: "{{ compress_tasks }}"
  loop_control:
    loop_var: compress_result

# Finalise report
- name: Write line to report
  blockinfile:
    marker: "<!-- {combination-init} ANSIBLE MANAGED BLOCK -->"
    path: "{{ log_path }}/combination_report.html"
    block: |
      <p>Combine play ended on: {{ now(utc=True).isoformat() }}</p>

- include_tasks: finalise-{{ output_destination }}.yaml
