---

# The assumption here is that an extract has been done and
# a number of compressed (.gz) node and edge (relationship) files exist
# in the {{ copy_root }}/extract directory. The number of files will be
# dependent on the extract - the actual number is unimportant - the essential
# property of the extracted files is that their file-names contain the text
# 'nodes' or 'edges' (but not both) and they end '.gz'.
#
# Importantly, every '.gz' file we expect to find must have a corresponding
# 'header-' file in the role's 'files' directory.
#
# The tasks in this play are responsible for: -
#
# 1. templating the loader script (load-neo4j.sh) based on the files found
# 2. installing the graph header files (located in the role's 'files')
# 3. synchronising the files to AWS S3

# List all the node files into ' node-files.txt'.
# This is a 1-file-per-line list of extracted nodes.

- name: Collect node files
  shell: ls -1 *nodes*.gz > node-files.txt
  args:
    chdir: "{{ copy_root }}/extract"
  become: yes
  become_user: "{{ db_user_account }}"
  delegate_to: "{{ groups['dbservers'][0] }}"

# Create the 'node_text' variable that will be used when templating
# the loader script. This is essentially a '--nodes' directive for
# each line in 'node-files.txt'. If 'node-files.txt'
# is: -
#
#    nodes.csv.gz
#    isomol-nodes.csv.gz
#
# Then the 'nodes' variable should look like this
# (with each line indented by 8 spaces)...
#
#    --nodes "header-nodes.csv,nodes.csv.gz" \
#    --nodes "header-isomol-nodes.csv,isomol-nodes.csv.gz" \

- name: Form node_result
  shell: >-
    paste -d , node-files.txt node-files.txt
    | sed 's/.gz,/,/g'
    | sed 's/^/        --nodes "header-/g'
    | sed 's/$/" \\/g'
  register: node_result
  args:
    chdir: "{{ copy_root }}/extract"
  become: yes
  become_user: "{{ db_user_account }}"
  delegate_to: "{{ groups['dbservers'][0] }}"

- name: Set node_text
  set_fact:
    node_text: "{{ node_result.stdout }}"

# List all the edge files into 'edge-files.txt'.
# This is a 1-file-per-line list of extracted edges.

- name: Collect edge files
  shell: ls -1 *edges*.gz > edge-files.txt
  args:
    chdir: "{{ copy_root }}/extract"
  become: yes
  become_user: "{{ db_user_account }}"
  delegate_to: "{{ groups['dbservers'][0] }}"

- name: Form relationship_result
  shell: >-
    paste -d , edge-files.txt edge-files.txt
    | sed 's/^/        --relationships "header-/g'
    | sed 's/$/" \\/g'
    | sed '$ s/.$//'
  register: relationship_result
  args:
    chdir: "{{ copy_root }}/extract"
  become: yes
  become_user: "{{ db_user_account }}"
  delegate_to: "{{ groups['dbservers'][0] }}"

- name: Set relationship_text
  set_fact:
    relationship_text: "{{ relationship_result.stdout }}"

# Now template the script using the node & relationship variables
# and copy all the header files we have
# (some may not be used - just copy them all anyway)...

- name: Install the loader script
  template:
    src: load-neo4j.sh.j2
    dest: "{{ copy_root }}/extract/load-neo4j.sh"
    mode: 0555
    owner: "{{ db_user_account }}"
    group: "{{ db_user_account }}"
  become: yes
  delegate_to: "{{ groups['dbservers'][0] }}"

- name: Copy header files
  copy:
    src: "{{ item }}"
    dest: "{{ copy_root }}/extract/{{ item|basename }}"
    mode: 0444
    owner: "{{ db_user_account }}"
    group: "{{ db_user_account }}"
  with_fileglob:
  - header-*
  become: yes
  delegate_to: "{{ groups['dbservers'][0] }}"

- name: Remove node and edge text files
  command: rm node-files.txt edge-files.txt
  args:
    chdir: "{{ copy_root }}/extract"
  become: yes
  become_user: "{{ db_user_account }}"
  delegate_to: "{{ groups['dbservers'][0] }}"

# Synchronise the extract to S3

- name: Upgrade PIP
  command: pip install --upgrade pip
  become: yes
  delegate_to: "{{ groups['dbservers'][0] }}"

- name: Install S3 requirements
  pip:
    name:
    - dateutil
  become: yes
  delegate_to: "{{ groups['dbservers'][0] }}"

- name: Synchronise extract to S3
  s3_sync:
    bucket: "{{ bucket }}"
    key_prefix: extract/{{ vendor }}/{{ version }}
    file_root: "{{ copy_root }}/extract"
    aws_access_key: "{{ aws_access_key }}"
    aws_secret_key: "{{ aws_secret_key }}"
    region: "{{ aws_region }}"
  become: yes
  delegate_to: "{{ groups['dbservers'][0] }}"
