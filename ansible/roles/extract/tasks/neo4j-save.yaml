---

# The assumption here is that an extract has been done and
# a number of compressed (.gz) node and edge (relationship) files exist
# in the {{ copy_root }}/extract directory. The number of files will be
# dependent on the extract - the actual number is unimportant - the essential
# property of the extracted files is that their file-names contain the text
# 'nodes' or 'edges' (but not both) and they end '.gz'.
#
# Importantly, every '.gz' file we expect to find must have a corresponding
# 'header-' file in the role's 'files' directory. So, if there's an 'x.csv.gz'
# in the extract there must be a 'header-x.csv' in 'files'.
#
# The tasks in this play are responsible for: -
#
# 1. compressing the extract
# 2. templating the loader script (load-neo4j.sh) based on the files found
# 3. installing the graph header files (located in the role's 'files')
# 4. synchronising the files to AWS S3

# Pack all files to '.gz' files -1 should compress more quickly.
# We run this on (delegate to) the DB server...

- name: Compress extracted csv files
  shell: gzip *.csv
  args:
    chdir: "{{ copy_root }}/extract"
  become: true
  become_user: "{{ database[deployment].db_user_account }}"

# List all the node files into ' node-files.txt'.
# This is a 1-file-per-line list of extracted nodes.

- name: Collect node files
  shell: ls -1 *nodes*.gz > node-files.txt
  args:
    chdir: "{{ copy_root }}/extract"
  become: true
  become_user: "{{ database[deployment].db_user_account }}"

# Create the 'node_text' variable that will be used when templating
# the loader script. This is essentially a '--nodes' directive for
# each line in 'node-files.txt'. If 'node-files.txt'
# is: -
#
#    nodes.csv.gz
#    isomol-nodes.csv.gz
#
# Then the 'nodes' variable should look like this
# (with each line indented by 8 spaces)...
#
#    --nodes "header-nodes.csv,nodes.csv.gz" \
#    --nodes "header-isomol-nodes.csv,isomol-nodes.csv.gz" \

- name: Form node_result
  shell: >-
    set -o pipefail &&
    paste -d , node-files.txt node-files.txt
    | sed 's/.gz,/,/g'
    | sed 's/^/        --nodes "header-/g'
    | sed 's/$/" \\/g'
  register: node_result
  args:
    chdir: "{{ copy_root }}/extract"
  become: true
  become_user: "{{ database[deployment].db_user_account }}"

- name: Set node_text
  set_fact:
    node_text: "{{ node_result.stdout }}"

# List all the edge files into 'edge-files.txt'.
# This is a 1-file-per-line list of extracted edges.

- name: Collect edge files
  shell: ls -1 *edges*.gz > edge-files.txt
  args:
    chdir: "{{ copy_root }}/extract"
  become: true
  become_user: "{{ database[deployment].db_user_account }}"

- name: Form relationship_result
  shell: >-
    paste -d , edge-files.txt edge-files.txt
    | sed 's/.gz,/,/g'
    | sed 's/^/        --relationships "header-/g'
    | sed 's/$/" \\/g'
    | sed '$ s/.$//'
  register: relationship_result
  args:
    chdir: "{{ copy_root }}/extract"
  become: true
  become_user: "{{ database[deployment].db_user_account }}"

- name: Set relationship_text
  set_fact:
    relationship_text: "{{ relationship_result.stdout }}"

# Now template the script using the node & relationship variables
# and copy all the header files we have
# (some may not be used - just copy them all anyway)...

- name: Install the loader script
  template:
    src: load-neo4j.sh.j2
    dest: "{{ copy_root }}/extract/load-neo4j.sh"
    mode: 0555
    owner: "{{ database[deployment].db_user_account }}"
    group: "{{ database[deployment].db_user_account }}"

- name: Copy header files
  copy:
    src: "{{ item }}"
    dest: "{{ copy_root }}/extract/{{ item|basename }}"
    mode: 0444
    owner: "{{ database[deployment].db_user_account }}"
    group: "{{ database[deployment].db_user_account }}"
  with_fileglob:
  - header-*
  become: yes

- name: Copy vendor specific suppliermol-supplier-edges header file if single vendor
  copy:
    src: "{{ item }}"
    dest: "{{ copy_root }}/extract/{{ item|basename }}"
    mode: 0444
    owner: "{{ database[deployment].db_user_account }}"
    group: "{{ database[deployment].db_user_account }}"
  with_fileglob:
  - "{{ extracts[0].lib.vendor }}/header-*"
  become: yes
  when: source_id_lst|length == 1

- name: Copy combined suppliermol-supplier-edges header file if combination
  copy:
    src: "{{ item }}"
    dest: "{{ copy_root }}/extract/{{ item|basename }}"
    mode: 0444
    owner: "{{ database[deployment].db_user_account }}"
    group: "{{ database[deployment].db_user_account }}"
  with_fileglob:
  - "{{ combined_vendor }}/header-*"
  become: yes
  when: source_id_lst|length > 1

- name: Remove node and edge text files
  command: rm node-files.txt edge-files.txt
  args:
    chdir: "{{ copy_root }}/extract"
  become_user: "{{ database[deployment].db_user_account }}"
  become: true
  delegate_to: "{{ groups['dbservers'][0] }}"

# Synchronise the extract to S3

# When only one vendor, use it
- name: Synchronise extract to S3 - Single Vendor
  s3_sync:
    bucket: "{{ bucket }}"
    key_prefix: extract/{{ extracts[0].lib.vendor }}/{{ extracts[0].lib.version }}
    file_root: "{{ copy_root }}/extract"
    aws_access_key: "{{ aws_access_key }}"
    aws_secret_key: "{{ aws_secret_key }}"
    region: "{{ aws_region }}"
  when: source_id_lst|length == 1

# When combination, use combination/first vendor/first version
- name: Synchronise extract to S3 - Combination
  s3_sync:
    bucket: "{{ bucket }}"
    key_prefix: extract/combination/{{ extracts[0].lib.vendor }}/{{ ansible_date_time.date }}
    file_root: "{{ copy_root }}/extract"
    aws_access_key: "{{ aws_access_key }}"
    aws_secret_key: "{{ aws_secret_key }}"
    region: "{{ aws_region }}"
  when: source_id_lst|length > 1
