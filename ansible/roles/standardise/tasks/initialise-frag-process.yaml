---
# Initialise Fragmentation Process

- debug:
    msg: "{{ reppath }}/run/vendor/{{ vendor }}"

# Check run path
- name: Ensure runpath is present
  file:
    path: "{{ item }}"
    state: directory
  loop:
  - "{{ runpath }}"

# Install the required modules to be able to synchronise the data from S3 and use ansible python modules
# Note that on prod this is done as "sudo" (become = yes)
- name: Install requirements
  pip:
    name:
    - python-dateutil==2.8.1
    - boto3==1.12.49
    - psycopg2-binary==2.8.5
  when: deployment=="production"

- name: Install requirements
  pip:
    name:
    - python-dateutil==2.8.1
    - boto3==1.12.49
    - psycopg2-binary==2.8.5
  when: deployment=="development"

# Check the vendor name is one that can be processed.
- name: check vendor_name
  postgresql_query:
    query: >-
      select count(*) from vendor_name
      where vendor_name = '{{ vendor }}';
    autocommit: no
  register: query_result

- debug:
    var: query_result

# If check the vendor name is present
- name: vendor_name is present in database
  assert:
    that:
    - "{{ query_result.query_result[0].count|int }} == 1"
    fail_msg: The vendor must be configured in the vendor_name table.

# Check if the data library version for the vendor has been processed before.
- name: check if previous version
  postgresql_query:
    query: select id from source where name = '{{ vendor }}' and version = '{{ version }}';
    autocommit: no
  register: query_result

- debug:
    var: query_result

# If add_file is no (normal situation) then check the version had not been processed before
- name: version already processed sanity-check
  assert:
    that:
    - "{{ query_result.rowcount|int }} == 0"
    fail_msg: This version has already been processed once. If you are adding a file to this library, use the add_file parameter.
  when: not add_file|bool

# If add_file is true then use the existing source id from the previous run
- name: Set source_id
  set_fact:
    source_id: "{{ query_result.query_result[0].id }}"
  when: add_file|bool

- name: Variable sanity-check
  assert:
    that:
    - "{{ vendors[vendor].fraghac|int }} > 0"
    - "{{ vendors[vendor].fragminhac|int }} >= 0"
    - "{{ vendors[vendor].fragmaxfrags|int }} > 0"
    - "{{ vendors[vendor].fraglimit|int }} >= 0"

- name: Get Fragmentor commit reference
  command: git log --pretty=format:'%h' -n 1
  args:
    chdir: "{{ reppath }}"
  register: fragmentor_commit_result
  changed_when: false

- name: Set Fragmentor Facts
  set_fact:
    fragmentor_commit_ref: "{{ fragmentor_commit_result.stdout }}"

# If add_file is no (normal situation) and the version has not been processed then add to the source table.
- name: Insert run parameters
  postgresql_query:
    query: >-
      insert into source (name, version, min_hac, max_hac, max_frags, frag_limit, start_datetime, fragmentor_commit_ref )
      values ('{{ vendor }}', '{{ version }}',{{ vendors[vendor].fragminhac|int }},
              {{ vendors[vendor].fraghac|int }},{{ vendors[vendor].fragmaxfrags|int }},
              {{ vendors[vendor].fraglimit|int }}, now() at time zone 'utc', '{{ fragmentor_commit_ref }}' )
      returning id;
    autocommit: yes
  register: query_result
  when: not add_file|bool

# If add_file is true then use the existing source id from the previous run
- name: Set source_id
  set_fact:
    source_id: "{{ query_result.query_result[0].id }}"
  when: not add_file|bool

- name: Display source_id
  debug:
    var: source_id

# Optionally erase and then create the working directories...
- name: Erase directories
  file:
    path: "{{ item }}"
    state: absent
  loop:
  - "{{ datapath }}/data/{{ vendor }}"
  - "{{ standpath }}/standardise"
  - "{{ logpath }}/{{ vendor }}/{{ version }}/standardise"
  when: clean_start|bool

- name: Create directories
  file:
    path: "{{ item }}"
    state: directory
  loop:
  - "{{ datapath }}/data/{{ vendor }}"
  - "{{ standpath }}/standardise"
  - "{{ logpath }}/log/{{ vendor }}/{{ version }}/standardise"

- name: Ensure sql and nextflow directories are present
  file:
    path: "{{ item }}"
    state: directory
  loop:
  - "{{ reppath }}/sql"
  - "{{ reppath }}/nextflow"

# Create Standardisation Summary Report. This is saved with the playbook results.
- name: Create Standardise HTML log report
  blockinfile:
    path: "{{ standpath }}/standardise/standardise_report.html"
    create: yes
    marker: "<!-- {standardise-init} ANSIBLE MANAGED BLOCK -->"
    insertafter: "<body>"
    block: |
      <h1>Ansible Standardisation Playbook</h1>
      <p><table>
      <tr><th>Parameter</th><th>Value</th></tr>
      <tr><td>Vendor</td><td>{{ vendor }}</td></tr>
      <tr><td>Version</td><td>{{ version }}</td></tr>
      <tr><td>Source-id</td><td>{{ source_id }}</td></tr>
      <tr><td>User</td><td>{{ inventory_hostname }}</td></tr>
      <tr><td>Deployment</td><td>{{ deployment }}</td></tr>
      </table></p>
      <p>Standardisation play started on: {{ now(utc=True).isoformat() }}</p>
  when: clean_start|bool
