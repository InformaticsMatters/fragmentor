---

# Variables shared with all roles

# The deployment type.
# This is used to select material based on whether
# we're launching plays for: -
# - development
# - production
#
# The deployment value should be an entry in the database map (see below)
deployment: SetMe

# Erase any files/content generated in a prior run?
# If set to yes this tends to remove temporary data directories,
# it does not erase or adjust databases or tables -
# it's simply about a clean 'disk'.
clean_start: yes

# If set to yes this tends to remove temporary/work data directories.
# Not essential files.
clean_finish: no

# The details of the fragmentation container,
# used for a number of nextflow workflows.
# You can provide registry, name and tag.
# The netflow container registry can be set by the user.
# Blank assumes no registry (i.e. 'docker.io')
nextflow_container_registry: ''
nextflow_container_name: informaticsmatters/fragmentor
nextflow_container_tag: '2.0.4'

# Memory requested by the 'sort' processes in the nextflow workflow
# (namely fragmentation and combination). Where it's actually used
# it is used to set the process memory request for nextflow
# and a smaller value (typically 80% of the value you specify here)
# used for the sort commands in the process.
# Minimum value is 100.
nextflow_process_sort_memory_m: 81920

# Cloud provider for the database server.
# Typically one of 'openstack' or 'aws'
database_cloud_provider: openstack

# The hostname of the database server.
# One of production or development.
database_login_host: SetMe

# The destination of play results (typically an S3 bucket).
# One of 'disk' or 's3'
#
# It's defined here but (currently) is only
# employed by the combination play.
data_source_out: s3

# Database credentials.
# A map of variables based on deployment target.
database:
  development:
    port: 5432
    db: mydatabase
    login_user: postgres
    login_password: 1234
    copy_directory: /var/lib/postgresql/data
    backup_directory: /home/duncan/Documents/pgdata-backup
    backup_count: 2
    db_user_account: postgres
  production:
    port: 5432
    db: fairmolecules
    login_user: fragmentor
    login_password: bullfinch
    copy_directory: /pgcopy
    backup_directory: /pgdata-backup
    backup_count: 2
    db_user_account: fragmentor

# A default set of devices.
# Normally specified in a host-specific file in host_vars
#
# The DB server's database, backup, pgcopy and wal volume
# devices, and mount-points
db_devices:
  pg_data:
    device:
    mount_path: /pgdata
  pg_wal:
    device:
    mount_path: /pgwal
  pg_backup:
    device:
    mount_path: /pgdata-backup

# Hardware sizing - used to calculate size of chunks in standardization/fragmentation.
# A map of variables based on deployment target.

# Note that cluster_cores has been removed.
# The size of the cluster is defined in the nextflow config which is
# installed by the user on the machine used to run the jobs.
# Something like /home/<user>/.nextflow./config

hardware:
  development:
    # Parallel_jobs is used in calculating chunk sizes for processing -
    # If this is less than cluster_cores, then not all the cluster
    # will be used.
    parallel_jobs: 8
    # Number of connections to postgres -
    # note that this should be less than max_worker_processes in start-database.yaml.
    postgres_jobs: 6
  production:
    # 100 parallel jobs should be sufficient to process all but the
    # largest libraries (full enamine/molport load).
    # For role combine, ideally this might be increased
    # when combining large databases - otherwise there might be a timeout.
    parallel_jobs: 100
    postgres_jobs: 20

# Vendor defaults.
# A map of defaults based on the vendor and library.
vendors:
  xchem_dsip:
    # Used for sizing timeouts and processing parameters
    approx_vendor_molecules: 800
    # Total time (in minutes) across all CPUs -
    # Used for sizing timeouts and processing parameters
    est_total_fragmentation_time: 10
    # Minimum heavy atom count for extraction/fragmentation processing
    fragminhac: 0
    # Maximum heavy atom count for extraction/fragmentation processing
    fraghac: 36
    # Maximum frag cycles for fragmentation processing
    fragmaxfrags: 12
    # Limit for partial fragmentation processing (not operational)
    fraglimit: 0
    # Extract Playbook: Chunk of molecules to be processed before insert to index
    # This is a sensitive value - settings for each vendor should be tuned.
    # So the values below are set based on the number of edges per mol_source value
    # and validated by testing.
    indexchunksize: 100
    # Total time (in minutes) to build index (will be divided by number of postgres_jobs)
    index_build_time: 10
  xchem_spot:
    approx_vendor_molecules: 96
    est_total_fragmentation_time: 10
    fragminhac: 0
    fraghac: 36
    fragmaxfrags: 12
    fraglimit: 0
    indexchunksize: 100
    index_build_time: 10
  xchem_leeds:
    approx_vendor_molecules: 96
    est_total_fragmentation_time: 10
    fragminhac: 0
    fraghac: 36
    fragmaxfrags: 12
    fraglimit: 0
    indexchunksize: 100
    index_build_time: 10
  xchem_covhet:
    approx_vendor_molecules: 96
    est_total_fragmentation_time: 10
    fragminhac: 0
    fraghac: 36
    fragmaxfrags: 12
    fraglimit: 0
    indexchunksize: 100
    index_build_time: 10
  xchem_probe:
    approx_vendor_molecules: 239
    est_total_fragmentation_time: 10
    fragminhac: 0
    fraghac: 36
    fragmaxfrags: 12
    fraglimit: 0
    indexchunksize: 100
    index_build_time: 10
  xchem_cyselectrophile:
    approx_vendor_molecules: 96
    est_total_fragmentation_time: 10
    fragminhac: 0
    fraghac: 36
    fragmaxfrags: 12
    fraglimit: 0
    indexchunksize: 100
    index_build_time: 10
  xchem_eubopendsipext:
    approx_vendor_molecules: 96
    est_total_fragmentation_time: 10
    fragminhac: 0
    fraghac: 36
    fragmaxfrags: 12
    fraglimit: 0
    indexchunksize: 100
    index_build_time: 10
  xchem_euopenscreen:
    approx_vendor_molecules: 96
    est_total_fragmentation_time: 10
    fragminhac: 0
    fraghac: 36
    fragmaxfrags: 12
    fraglimit: 0
    indexchunksize: 100
    index_build_time: 10
  chemspace_bb:
    approx_vendor_molecules: 18000000
    est_total_fragmentation_time: 7500
    fragminhac: 0
    fraghac: 36
    fragmaxfrags: 12
    fraglimit: 0
    indexchunksize: 5000
    index_build_time: 480
  molport:
    approx_vendor_molecules: 8000000
    est_total_fragmentation_time: 360000
    fragminhac: 0
    fraghac: 36
    fragmaxfrags: 12
    fraglimit: 0
    indexchunksize: 3000
    index_build_time: 4320
  enamine_ro5:
    approx_vendor_molecules: 40000000
    est_total_fragmentation_time: 720000
    fragminhac: 0
    fraghac: 36
    fragmaxfrags: 12
    fraglimit: 0
    indexchunksize: 3000
    index_build_time: 17280
  enamine_mferla:
    approx_vendor_molecules: 20000000
    est_total_fragmentation_time: 360000
    fragminhac: 0
    fraghac: 36
    fragmaxfrags: 12
    fraglimit: 0
    indexchunksize: 3000
    index_build_time: 17280
  # For Rubens new library / per chunk
  enamine:
    approx_vendor_molecules: 50000000
    est_total_fragmentation_time: 3880000
    fragminhac: 0
    fraghac: 36
    fragmaxfrags: 12
    fraglimit: 0
    indexchunksize: 3000
    index_build_time: 80000
  sdf:
    approx_vendor_molecules: 50
    est_total_fragmentation_time: 10
    fragminhac: 0
    fraghac: 36
    fragmaxfrags: 12
    fraglimit: 0
    indexchunksize: 100
    index_build_time: 10

# The tag of the fragmentation container,
neo4j_graph_version: 2019-12-18.2

# Email configuration
#
# Credentials to enable SMTP email transmission.
# All of there are expected to be defined in the user's parameters file
# or, via the environment.
# If any of them are unset/blank, mail is not sent.
# Username is the owner of the email account, not a recipient.
# mail_recipients is a comma-separated list of email addresses.
mail_host: "{{ lookup('env', 'GRAPH_MAIL_HOST') }}"
mail_port: "{{ lookup('env', 'GRAPH_MAIL_PORT') or '587' }}"
mail_username: "{{ lookup('env', 'GRAPH_MAIL_USERNAME') }}"
mail_password: "{{ lookup('env', 'GRAPH_MAIL_PASSWORD') }}"
mail_recipients: "{{ lookup('env', 'GRAPH_MAIL_RECIPIENTS') }}"

# S3 storage
#
# The S3 bucket and whether it requires encryption,
# along with S3 access keys, a Region and S3 URL (blank if using AWS).
#
# We use environment variables that are inspected by Ansible 2.9,
# but they are not used for variables in the aws_s3 module when
# the module reads them anyway. i.e. we do not set the aws_s3
# 'aws_access_key' variable because Ansible reads 'AWS_ACCESS_KEY'.
# We load them here to allow us to assert the values are set during the
# playbook initialisation logic.
s3_bucket: im-fragnet
s3_bucket_requires_encryption: no
s3_access_key: "{{ lookup('env', 'AWS_ACCESS_KEY') }}"
s3_secret_key: "{{ lookup('env', 'AWS_SECRET_KEY') }}"
s3_region: "{{ lookup('env', 'AWS_REGION')|default('eu-central-1', true) }}"
s3_url: "{{ lookup('env', 'S3_URL') }}"
